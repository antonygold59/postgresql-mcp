{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "intro",
            "metadata": {},
            "source": [
                "# postgres-mcp Quickstart & Cookbook\n",
                "\n",
                "This notebook demonstrates how to programmatically interact with the `postgres-mcp` server using the Python MCP SDK. \n",
                "\n",
                "It covers:\n",
                "1.  **Connecting** to the server.\n",
                "2.  **Listing Tools** available (195 tools!).\n",
                "3.  **Reading Data** via SQL.\n",
                "4.  **Writing Data** (DDL/DML).\n",
                "5.  **Reading Resources** (Observability).\n",
                "6.  **Error Handling**.\n",
                "7.  **Transactions** (Atomic operations).\n",
                "8.  **AI Prompts** (Built-in workflows).\n",
                "9.  **Performance Analysis** (EXPLAIN ANALYZE).\n",
                "10. **JSONB Support** (PostgreSQL's superior JSON).\n",
                "11. **Vector Search (pgvector)** (AI/ML Similarity Search).\n",
                "12. **Fulltext Search** (tsvector/tsquery).\n",
                "13. **PostGIS Spatial Data** (GIS/Location Search).\n",
                "14. **Code Mode** (Multi-step sandboxed operations).\n",
                "\n",
                "## Prerequisites\n",
                "\n",
                "- Node.js 18+ (for running the server)\n",
                "- Python 3.10+\n",
                "- A running PostgreSQL instance (12-18)\n",
                "- `postgres-mcp` built locally (`npm run build`)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "install",
            "metadata": {},
            "source": [
                "## 1. Install Dependencies\n",
                "\n",
                "Install `mcp` for the protocol and `python-dotenv` for managing credentials."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "pip-install",
            "metadata": {},
            "outputs": [],
            "source": [
                "%pip install mcp python-dotenv"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "setup",
            "metadata": {},
            "source": [
                "## 2. Configuration & Setup\n",
                "\n",
                "We define the server connection parameters here. We use `python-dotenv` to load credentials from the project's `.env` file automatically."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "config_code",
            "metadata": {},
            "outputs": [],
            "source": [
                "import asyncio\n",
                "import os\n",
                "import json\n",
                "from contextlib import asynccontextmanager\n",
                "from dotenv import load_dotenv\n",
                "from mcp import ClientSession, StdioServerParameters\n",
                "from mcp.client.stdio import stdio_client\n",
                "\n",
                "# 1. Load Environment\n",
                "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\"))\n",
                "env_path = os.path.join(project_root, \".env\")\n",
                "load_dotenv(env_path)\n",
                "\n",
                "# 2. Build Connection String\n",
                "user = os.getenv(\"POSTGRES_USER\", \"postgres\")\n",
                "password = os.getenv(\"POSTGRES_PASSWORD\", \"password\")\n",
                "host = os.getenv(\"POSTGRES_HOST\", \"localhost\")\n",
                "port = os.getenv(\"POSTGRES_PORT\", \"5432\")\n",
                "database = os.getenv(\"POSTGRES_DATABASE\", \"postgres\")\n",
                "connection_string = f\"postgres://{user}:{password}@{host}:{port}/{database}\"\n",
                "\n",
                "# 3. Server Parameters\n",
                "SERVER_SCRIPT = os.path.join(project_root, \"dist\", \"cli.js\")\n",
                "server_params = StdioServerParameters(\n",
                "    command=\"node\",\n",
                "    args=[SERVER_SCRIPT, \"--transport\", \"stdio\", \"--postgres\", connection_string],\n",
                "    env=os.environ.copy()\n",
                ")\n",
                "\n",
                "print(f\"Configured to connect to: postgres://{user}:***@{host}:{port}/{database}\")\n",
                "\n",
                "# 4. Helper Context Manager\n",
                "@asynccontextmanager\n",
                "async def mcp_client():\n",
                "    \"\"\"Helper to manage the MCP client session lifecycle.\"\"\"\n",
                "    # Redirect stderr to devnull to fix Windows/Jupyter 'fileno' issue\n",
                "    with open(os.devnull, \"w\") as devnull:\n",
                "        async with stdio_client(server_params, errlog=devnull) as (read, write):\n",
                "            async with ClientSession(read, write) as session:\n",
                "                await session.initialize()\n",
                "                yield session"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "list_tools",
            "metadata": {},
            "source": [
                "## 3. List Available Tools\n",
                "\n",
                "Let's verify the connection by listing the tools the server provides. PostgreSQL MCP exposes **195 specialized tools**!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "tools_code",
            "metadata": {},
            "outputs": [],
            "source": [
                "async def list_tools_example():\n",
                "    async with mcp_client() as session:\n",
                "        result = await session.list_tools()\n",
                "        print(f\"Connected! Found {len(result.tools)} tools.\\n\")\n",
                "        \n",
                "        # Print first few tools\n",
                "        for tool in result.tools[:5]:\n",
                "            print(f\"[Tool] {tool.name}: {tool.description[:60]}...\")\n",
                "\n",
                "# Run execution (handles Jupyter async loop)\n",
                "if __name__ == \"__main__\" and 'get_ipython' in globals():\n",
                "    await list_tools_example()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "read_data",
            "metadata": {},
            "source": [
                "## 4. Reading Data (SELECT)\n",
                "\n",
                "Use `pg_read_query` to run SELECT statements safely with prepared statements."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "read_code",
            "metadata": {},
            "outputs": [],
            "source": [
                "async def read_data_example():\n",
                "    async with mcp_client() as session:\n",
                "        print(\"--- Executing SELECT query ---\")\n",
                "        # First, list tables to find a valid table name\n",
                "        tables_res = await session.call_tool(\"pg_list_tables\", {})\n",
                "        tables_data = json.loads(tables_res.content[0].text)\n",
                "        \n",
                "        if not tables_data.get(\"tables\"):\n",
                "            print(\"No tables found. Querying pg_catalog instead.\")\n",
                "            query_res = await session.call_tool(\"pg_read_query\", {\n",
                "                \"query\": \"SELECT tablename FROM pg_catalog.pg_tables LIMIT 5\"\n",
                "            })\n",
                "        else:\n",
                "            first_table = tables_data[\"tables\"][0][\"name\"]\n",
                "            print(f\"Querying table: {first_table}\")\n",
                "            query_res = await session.call_tool(\"pg_read_query\", {\n",
                "                \"query\": f\"SELECT * FROM {first_table} LIMIT 3\"\n",
                "            })\n",
                "        \n",
                "        print(\"Result:\")\n",
                "        print(query_res.content[0].text)\n",
                "\n",
                "if __name__ == \"__main__\" and 'get_ipython' in globals():\n",
                "    await read_data_example()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "write_data",
            "metadata": {},
            "source": [
                "## 5. Writing Data (CREATE / INSERT)\n",
                "\n",
                "Use `pg_write_query` for DDL and DML operations. Let's create a temporary table and insert data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "write_code",
            "metadata": {},
            "outputs": [],
            "source": [
                "async def write_data_example():\n",
                "    async with mcp_client() as session:\n",
                "        table_name = \"notebook_demo_table\"\n",
                "        \n",
                "        print(f\"--- Creating table '{table_name}' ---\")\n",
                "        await session.call_tool(\"pg_write_query\", {\n",
                "            \"query\": f\"CREATE TABLE IF NOT EXISTS {table_name} (id SERIAL PRIMARY KEY, message VARCHAR(255))\"\n",
                "        })\n",
                "        print(\"Table created.\")\n",
                "        \n",
                "        print(\"--- Inserting data ---\")\n",
                "        await session.call_tool(\"pg_write_query\", {\n",
                "            \"query\": f\"INSERT INTO {table_name} (message) VALUES ('Hello from Jupyter'), ('MCP is cool')\"\n",
                "        })\n",
                "        print(\"Data inserted.\")\n",
                "        \n",
                "        print(\"--- Verifying data ---\")\n",
                "        result = await session.call_tool(\"pg_read_query\", {\n",
                "            \"query\": f\"SELECT * FROM {table_name}\"\n",
                "        })\n",
                "        print(result.content[0].text)\n",
                "        \n",
                "        # Cleanup\n",
                "        await session.call_tool(\"pg_drop_table\", {\"table\": table_name})\n",
                "        print(\"Cleanup complete.\")\n",
                "\n",
                "if __name__ == \"__main__\" and 'get_ipython' in globals():\n",
                "    await write_data_example()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "resources",
            "metadata": {},
            "source": [
                "## 6. Reading Resources\n",
                "\n",
                "MCP Resources provide direct access to data like system status or schema info. \n",
                "Key PostgreSQL resources: `postgres://health`, `postgres://extensions`, `postgres://stats`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "resource_code",
            "metadata": {},
            "outputs": [],
            "source": [
                "async def read_resources_example():\n",
                "    async with mcp_client() as session:\n",
                "        print(\"--- Reading 'postgres://health' Resource ---\")\n",
                "        \n",
                "        # Read the health resource\n",
                "        resource = await session.read_resource(\"postgres://health\")\n",
                "        \n",
                "        # Parse and display\n",
                "        data = json.loads(resource.contents[0].text)\n",
                "        print(f\"Server Version: {data.get('version')}\")\n",
                "        print(f\"Overall Status: {data.get('status')}\")\n",
                "        print(f\"Connection Pool: {data.get('connectionPool', {}).get('status')}\")\n",
                "        \n",
                "        print(\"\\n--- Reading 'postgres://extensions' Resource ---\")\n",
                "        ext_resource = await session.read_resource(\"postgres://extensions\")\n",
                "        ext_data = json.loads(ext_resource.contents[0].text)\n",
                "        print(f\"Available Extensions: {len(ext_data.get('available', []))}\")\n",
                "        print(f\"Installed Extensions: {[e['name'] for e in ext_data.get('installed', [])[:5]]}\")\n",
                "        \n",
                "if __name__ == \"__main__\" and 'get_ipython' in globals():\n",
                "    await read_resources_example()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "errors",
            "metadata": {},
            "source": [
                "## 7. Error Handling\n",
                "\n",
                "The server returns descriptive PostgreSQL-style errors for invalid queries."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "error_code",
            "metadata": {},
            "outputs": [],
            "source": [
                "async def error_handling_example():\n",
                "    async with mcp_client() as session:\n",
                "        print(\"--- Triggering Syntax Error ---\")\n",
                "        try:\n",
                "            result = await session.call_tool(\"pg_read_query\", {\n",
                "                \"query\": \"SELECT * FROM non_existent_table THIS_IS_INVALID_SQL\"\n",
                "            })\n",
                "            # MCP returns errors in the result content when isError is true\n",
                "            if result.isError:\n",
                "                print(f\"Error returned: {result.content[0].text}\")\n",
                "            else:\n",
                "                print(result.content[0].text)\n",
                "        except Exception as e:\n",
                "            print(f\"Caught Expected Error:\\n{e}\")\n",
                "\n",
                "if __name__ == \"__main__\" and 'get_ipython' in globals():\n",
                "    await error_handling_example()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "transactions",
            "metadata": {},
            "source": [
                "## 8. Transactions (Atomic Operations)\n",
                "\n",
                "PostgreSQL supports full ACID transactions with savepoints. Use `pg_transaction_begin`, `pg_transaction_commit`, and `pg_transaction_rollback`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "transaction_code",
            "metadata": {},
            "outputs": [],
            "source": [
                "async def transaction_example():\n",
                "    async with mcp_client() as session:\n",
                "        print(\"--- Executing Atomic Transaction ---\")\n",
                "        table = \"txn_demo\"\n",
                "        \n",
                "        # 1. Setup table (outside txn)\n",
                "        await session.call_tool(\"pg_write_query\", {\"query\": f\"CREATE TABLE IF NOT EXISTS {table} (val INT)\"})\n",
                "\n",
                "        # 2. Begin Transaction\n",
                "        await session.call_tool(\"pg_transaction_begin\", {})\n",
                "        print(\"Transaction started.\")\n",
                "        \n",
                "        # 3. Execute multiple statements\n",
                "        await session.call_tool(\"pg_write_query\", {\"query\": f\"INSERT INTO {table} (val) VALUES (100)\"})\n",
                "        await session.call_tool(\"pg_write_query\", {\"query\": f\"INSERT INTO {table} (val) VALUES (200)\"})\n",
                "        await session.call_tool(\"pg_write_query\", {\"query\": f\"UPDATE {table} SET val = val * 2\"})\n",
                "        \n",
                "        # 4. Commit\n",
                "        await session.call_tool(\"pg_transaction_commit\", {})\n",
                "        print(\"Transaction committed.\")\n",
                "        \n",
                "        # 5. Verify\n",
                "        check = await session.call_tool(\"pg_read_query\", {\"query\": f\"SELECT * FROM {table}\"})\n",
                "        print(\"\\nTable State (Expect 200, 400):\")\n",
                "        print(check.content[0].text)\n",
                "        \n",
                "        # Cleanup\n",
                "        await session.call_tool(\"pg_drop_table\", {\"table\": table})\n",
                "\n",
                "if __name__ == \"__main__\" and 'get_ipython' in globals():\n",
                "    await transaction_example()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "prompts",
            "metadata": {},
            "source": [
                "## 9. AI Prompts\n",
                "\n",
                "`postgres-mcp` exposes **19 built-in prompts** that help AI assistants generate better SQL, design schemas, and set up extensions."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "prompt_code",
            "metadata": {},
            "outputs": [],
            "source": [
                "async def prompt_example():\n",
                "    async with mcp_client() as session:\n",
                "        print(\"--- Listing Prompts ---\")\n",
                "        prompts = await session.list_prompts()\n",
                "        print(f\"Found {len(prompts.prompts)} prompts.\\n\")\n",
                "        \n",
                "        for p in prompts.prompts[:5]:\n",
                "            print(f\"- {p.name}: {p.description[:60]}...\")\n",
                "            \n",
                "        # Example: Extension setup prompts\n",
                "        print(\"\\n--- Extension Setup Prompts ---\")\n",
                "        setup_prompts = [p for p in prompts.prompts if 'setup' in p.name]\n",
                "        for p in setup_prompts:\n",
                "            print(f\"- {p.name}\")\n",
                "\n",
                "if __name__ == \"__main__\" and 'get_ipython' in globals():\n",
                "    await prompt_example()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "performance",
            "metadata": {},
            "source": [
                "## 10. Performance Analysis\n",
                "\n",
                "Use `pg_explain` to analyze query execution plans with PostgreSQL's powerful EXPLAIN ANALYZE."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "perf_code",
            "metadata": {},
            "outputs": [],
            "source": [
                "async def explain_example():\n",
                "    async with mcp_client() as session:\n",
                "        print(\"--- Executing EXPLAIN ANALYZE ---\")\n",
                "        # Explain a simple query on pg_catalog (guaranteed to exist)\n",
                "        result = await session.call_tool(\"pg_explain\", {\n",
                "            \"query\": \"SELECT * FROM pg_catalog.pg_tables WHERE schemaname = 'public'\",\n",
                "            \"analyze\": True,\n",
                "            \"format\": \"JSON\"\n",
                "        })\n",
                "        \n",
                "        # Show the execution plan\n",
                "        plan = json.loads(result.content[0].text)\n",
                "        print(json.dumps(plan, indent=2)[:800] + \"... [truncated]\")\n",
                "\n",
                "if __name__ == \"__main__\" and 'get_ipython' in globals():\n",
                "    await explain_example()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "jsonb_support",
            "metadata": {},
            "source": [
                "## 11. Working with JSONB (PostgreSQL's Superior JSON)\n",
                "\n",
                "PostgreSQL's JSONB type is binary, indexable, and supports rich path operators. `postgres-mcp` exposes dedicated `pg_jsonb_*` tools for document-style operations."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "jsonb_code",
            "metadata": {},
            "outputs": [],
            "source": [
                "async def jsonb_example():\n",
                "    async with mcp_client() as session:\n",
                "        table = \"jsonb_demo\"\n",
                "        \n",
                "        try:\n",
                "            print(\"--- Creating Table with JSONB Column ---\")\n",
                "            await session.call_tool(\"pg_write_query\", {\n",
                "                \"query\": f\"CREATE TABLE IF NOT EXISTS {table} (id SERIAL PRIMARY KEY, metadata JSONB)\"\n",
                "            })\n",
                "\n",
                "            print(\"--- Inserting JSONB Document ---\")\n",
                "            doc = {\n",
                "                \"user_id\": 42,\n",
                "                \"preferences\": {\"theme\": \"dark\", \"notifications\": True},\n",
                "                \"tags\": [\"developer\", \"mcp\"]\n",
                "            }\n",
                "            await session.call_tool(\"pg_jsonb_insert\", {\n",
                "                \"table\": table,\n",
                "                \"column\": \"metadata\",\n",
                "                \"data\": doc\n",
                "            })\n",
                "\n",
                "            print(\"--- Extracting Field with Path Operator ---\")\n",
                "            # Use PostgreSQL's -> and ->> operators\n",
                "            extract_res = await session.call_tool(\"pg_read_query\", {\n",
                "                \"query\": f\"SELECT metadata->'preferences'->>'theme' as theme FROM {table}\"\n",
                "            })\n",
                "            print(f\"Extracted Theme: {extract_res.content[0].text}\")\n",
                "\n",
                "            print(\"--- Querying with JSONB Containment ---\")\n",
                "            # Use @> containment operator\n",
                "            query_res = await session.call_tool(\"pg_jsonb_query\", {\n",
                "                \"table\": table,\n",
                "                \"column\": \"metadata\",\n",
                "                \"containment\": {\"tags\": [\"developer\"]}\n",
                "            })\n",
                "            print(f\"Found documents: {query_res.content[0].text}\")\n",
                "            \n",
                "        finally:\n",
                "            await session.call_tool(\"pg_drop_table\", {\"table\": table})\n",
                "\n",
                "if __name__ == \"__main__\" and 'get_ipython' in globals():\n",
                "    await jsonb_example()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "vector",
            "metadata": {},
            "source": [
                "## 12. Vector Search with pgvector (AI/ML)\n",
                "\n",
                "**pgvector** enables semantic similarity search for AI/ML applications like RAG. This is a killer feature for AI-powered applications.\n",
                "\n",
                "> ⚠️ **Prerequisite:** Requires pgvector extension installed (`CREATE EXTENSION vector`)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "vector_code",
            "metadata": {},
            "outputs": [],
            "source": [
                "async def vector_example():\n",
                "    async with mcp_client() as session:\n",
                "        table = \"vector_docs\"\n",
                "        \n",
                "        try:\n",
                "            # Check if pgvector is available\n",
                "            ext_check = await session.call_tool(\"pg_read_query\", {\n",
                "                \"query\": \"SELECT 1 FROM pg_extension WHERE extname = 'vector'\"\n",
                "            })\n",
                "            if 'rows' not in ext_check.content[0].text or '[]' in ext_check.content[0].text:\n",
                "                print(\"pgvector not installed. Run: CREATE EXTENSION vector;\")\n",
                "                return\n",
                "            \n",
                "            print(\"--- Creating Vector Table (384 dimensions) ---\")\n",
                "            await session.call_tool(\"pg_vector_create_table\", {\n",
                "                \"table\": table,\n",
                "                \"dimensions\": 384,\n",
                "                \"additionalColumns\": [\"title TEXT\", \"content TEXT\"]\n",
                "            })\n",
                "            \n",
                "            print(\"--- Creating HNSW Index ---\")\n",
                "            await session.call_tool(\"pg_vector_create_index\", {\n",
                "                \"table\": table,\n",
                "                \"column\": \"embedding\",\n",
                "                \"method\": \"hnsw\",\n",
                "                \"metric\": \"cosine\"\n",
                "            })\n",
                "\n",
                "            print(\"--- Inserting Sample Embeddings ---\")\n",
                "            # In real usage, these would come from an embedding model\n",
                "            sample_embedding = [0.1] * 384  # Simplified example\n",
                "            await session.call_tool(\"pg_vector_insert\", {\n",
                "                \"table\": table,\n",
                "                \"embedding\": sample_embedding,\n",
                "                \"metadata\": {\"title\": \"Machine Learning Intro\", \"content\": \"Neural networks...\"}\n",
                "            })\n",
                "\n",
                "            print(\"--- Similarity Search ---\")\n",
                "            query_embedding = [0.1] * 384\n",
                "            results = await session.call_tool(\"pg_vector_search\", {\n",
                "                \"table\": table,\n",
                "                \"column\": \"embedding\",\n",
                "                \"queryVector\": query_embedding,\n",
                "                \"limit\": 5,\n",
                "                \"metric\": \"cosine\"\n",
                "            })\n",
                "            print(results.content[0].text)\n",
                "            \n",
                "        finally:\n",
                "            await session.call_tool(\"pg_drop_table\", {\"table\": table})\n",
                "\n",
                "if __name__ == \"__main__\" and 'get_ipython' in globals():\n",
                "    await vector_example()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "fulltext",
            "metadata": {},
            "source": [
                "## 13. Fulltext Search (tsvector/tsquery)\n",
                "\n",
                "PostgreSQL's built-in full-text search uses `tsvector` and `tsquery` for powerful text searching with relevance ranking."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "fulltext_code",
            "metadata": {},
            "outputs": [],
            "source": [
                "async def fulltext_example():\n",
                "    async with mcp_client() as session:\n",
                "        table = \"fts_docs\"\n",
                "        \n",
                "        try:\n",
                "            print(\"--- Creating Table with tsvector Column ---\")\n",
                "            await session.call_tool(\"pg_write_query\", {\n",
                "                \"query\": f\"\"\"\n",
                "                    CREATE TABLE IF NOT EXISTS {table} (\n",
                "                        id SERIAL PRIMARY KEY,\n",
                "                        title TEXT,\n",
                "                        content TEXT,\n",
                "                        search_vector tsvector GENERATED ALWAYS AS (\n",
                "                            setweight(to_tsvector('english', coalesce(title, '')), 'A') ||\n",
                "                            setweight(to_tsvector('english', coalesce(content, '')), 'B')\n",
                "                        ) STORED\n",
                "                    )\n",
                "                \"\"\"\n",
                "            })\n",
                "            \n",
                "            print(\"--- Creating GIN Index ---\")\n",
                "            await session.call_tool(\"pg_fulltext_create_index\", {\n",
                "                \"table\": table,\n",
                "                \"column\": \"search_vector\"\n",
                "            })\n",
                "\n",
                "            print(\"--- Inserting Sample Documents ---\")\n",
                "            docs = [\n",
                "                (\"Machine Learning\", \"Introduction to supervised learning and neural networks.\"),\n",
                "                (\"Database Systems\", \"ACID properties ensure reliable database transactions.\"),\n",
                "                (\"Prompt Engineering\", \"Techniques for getting better output from LLMs.\")\n",
                "            ]\n",
                "            for title, content in docs:\n",
                "                await session.call_tool(\"pg_write_query\", {\n",
                "                    \"query\": f\"INSERT INTO {table} (title, content) VALUES ($1, $2)\",\n",
                "                    \"params\": [title, content]\n",
                "                })\n",
                "\n",
                "            print(\"--- Fulltext Search (Query: 'learning') ---\")\n",
                "            search_res = await session.call_tool(\"pg_fulltext_search\", {\n",
                "                \"table\": table,\n",
                "                \"column\": \"search_vector\",\n",
                "                \"query\": \"learning\",\n",
                "                \"selectColumns\": [\"title\", \"content\"]\n",
                "            })\n",
                "            print(search_res.content[0].text)\n",
                "                \n",
                "        finally:\n",
                "            await session.call_tool(\"pg_drop_table\", {\"table\": table})\n",
                "\n",
                "if __name__ == \"__main__\" and 'get_ipython' in globals():\n",
                "    await fulltext_example()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "spatial",
            "metadata": {},
            "source": [
                "## 14. PostGIS Spatial Data (GIS / Location Search)\n",
                "\n",
                "**PostGIS** is the gold standard for geospatial databases. `postgres-mcp` provides 12 dedicated tools for spatial operations.\n",
                "\n",
                "> ⚠️ **Prerequisite:** Requires PostGIS extension installed (`CREATE EXTENSION postgis`)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "spatial_code",
            "metadata": {},
            "outputs": [],
            "source": [
                "async def spatial_example():\n",
                "    async with mcp_client() as session:\n",
                "        table = \"spatial_places\"\n",
                "        \n",
                "        try:\n",
                "            # Check if PostGIS is available\n",
                "            ext_check = await session.call_tool(\"pg_read_query\", {\n",
                "                \"query\": \"SELECT 1 FROM pg_extension WHERE extname = 'postgis'\"\n",
                "            })\n",
                "            if 'rows' not in ext_check.content[0].text or '[]' in ext_check.content[0].text:\n",
                "                print(\"PostGIS not installed. Run: CREATE EXTENSION postgis;\")\n",
                "                return\n",
                "\n",
                "            print(\"--- Creating Spatial Table ---\")\n",
                "            await session.call_tool(\"pg_postgis_create_table\", {\n",
                "                \"table\": table,\n",
                "                \"geometryColumn\": \"location\",\n",
                "                \"geometryType\": \"POINT\",\n",
                "                \"srid\": 4326,\n",
                "                \"additionalColumns\": [\"name TEXT\"]\n",
                "            })\n",
                "\n",
                "            print(\"--- Creating Spatial Index ---\")\n",
                "            await session.call_tool(\"pg_postgis_create_index\", {\n",
                "                \"table\": table,\n",
                "                \"column\": \"location\"\n",
                "            })\n",
                "\n",
                "            print(\"--- Inserting Locations ---\")\n",
                "            # New York Landmarks (Longitude, Latitude)\n",
                "            places = [\n",
                "                (\"Empire State Building\", -73.9857, 40.7484),\n",
                "                (\"Central Park\", -73.9665, 40.7829),\n",
                "                (\"Statue of Liberty\", -74.0445, 40.6892)\n",
                "            ]\n",
                "            \n",
                "            for name, lon, lat in places:\n",
                "                await session.call_tool(\"pg_postgis_insert_point\", {\n",
                "                    \"table\": table,\n",
                "                    \"column\": \"location\",\n",
                "                    \"longitude\": lon,\n",
                "                    \"latitude\": lat,\n",
                "                    \"additionalData\": {\"name\": name}\n",
                "                })\n",
                "\n",
                "            print(\"--- Finding Nearby Places (within 5km of Times Square) ---\")\n",
                "            nearby = await session.call_tool(\"pg_postgis_nearby\", {\n",
                "                \"table\": table,\n",
                "                \"column\": \"location\",\n",
                "                \"longitude\": -73.9855,\n",
                "                \"latitude\": 40.7580,\n",
                "                \"radiusMeters\": 5000,\n",
                "                \"limit\": 5\n",
                "            })\n",
                "\n",
                "            print(\"Places within 5km of Times Square:\")\n",
                "            print(nearby.content[0].text)\n",
                "\n",
                "        finally:\n",
                "            await session.call_tool(\"pg_drop_table\", {\"table\": table})\n",
                "\n",
                "if __name__ == \"__main__\" and 'get_ipython' in globals():\n",
                "    await spatial_example()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "codemode",
            "metadata": {},
            "source": [
                "## 15. Code Mode (Multi-Step Sandboxed Operations)\n",
                "\n",
                "**Code Mode** is a unique feature that lets you write JavaScript to orchestrate multiple database operations in a single call. This can reduce token usage by 70-90% for complex operations!\n",
                "\n",
                "> ⚠️ **Prerequisite:** Requires `admin` OAuth scope when using OAuth authentication."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "codemode_code",
            "metadata": {},
            "outputs": [],
            "source": [
                "async def codemode_example():\n",
                "    async with mcp_client() as session:\n",
                "        print(\"--- Executing Code Mode: Get Table Row Counts ---\")\n",
                "        \n",
                "        # This single call replaces multiple individual tool calls\n",
                "        code = \"\"\"\n",
                "        // Get row counts for all tables in a single operation\n",
                "        const tables = await pg.core.listTables();\n",
                "        \n",
                "        // Limit to first 5 tables for demo\n",
                "        const subset = tables.slice(0, 5);\n",
                "        \n",
                "        return Promise.all(subset.map(async t => {\n",
                "            const result = await pg.core.readQuery({ \n",
                "                query: `SELECT COUNT(*) as count FROM ${t.schema}.${t.name}` \n",
                "            });\n",
                "            return {\n",
                "                table: `${t.schema}.${t.name}`,\n",
                "                rowCount: result[0]?.count || 0\n",
                "            };\n",
                "        }));\n",
                "        \"\"\"\n",
                "        \n",
                "        result = await session.call_tool(\"pg_execute_code\", {\n",
                "            \"code\": code\n",
                "        })\n",
                "        \n",
                "        print(\"Table Row Counts:\")\n",
                "        data = json.loads(result.content[0].text)\n",
                "        for item in data:\n",
                "            print(f\"  {item['table']}: {item['rowCount']} rows\")\n",
                "\n",
                "if __name__ == \"__main__\" and 'get_ipython' in globals():\n",
                "    await codemode_example()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "next_steps",
            "metadata": {},
            "source": [
                "## Next Steps\n",
                "\n",
                "Now that you've seen the basics, explore more:\n",
                "\n",
                "1. **Extension-Specific Tools**: pg_cron, pgcrypto, pg_partman, citext, ltree\n",
                "2. **Monitoring Resources**: `postgres://activity`, `postgres://locks`, `postgres://vacuum`\n",
                "3. **AI Prompts**: Use `pg_query_builder`, `pg_schema_design` for guided workflows\n",
                "4. **Performance Tuning**: `pg_index_recommendations`, `pg_stat_statements`\n",
                "\n",
                "See the [README](../../README.md) for full documentation of all 195 tools!"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}